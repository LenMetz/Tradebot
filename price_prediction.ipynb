{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b47683a",
   "metadata": {
    "id": "6b47683a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from model import Transformer, Conv, Temporal_Conv_Transformer, Temporal_Conv_Transformer_Vol\n",
    "from utils.prices_dataset import Prices, PricesVol\n",
    "from utils.loss_functions import CustomLoss, SignWeightedLoss, SignWeightedTgtLoss\n",
    "from train_test import train, test, test_conf, test_conf_ensemble, test_conf_val, test_conf_time, test_mus_stds_tgts\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a37e329",
   "metadata": {
    "id": "2a37e329",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vol = True\n",
    "epoch = 20\n",
    "lr = 0.0000005\n",
    "feature_size = 3\n",
    "out_channels = 3\n",
    "num_layers = 1\n",
    "nhead = 1\n",
    "dropout = 0.0\n",
    "batch_size = 512\n",
    "seq_length = 60\n",
    "shift = 30\n",
    "tgt_step = 3\n",
    "reg_weight=100\n",
    "center = True\n",
    "norm =  False\n",
    "#loss_func = SignWeightedLoss(weight=reg_weight)\n",
    "#loss_func = SignWeightedTgtLoss(weight=reg_weight)\n",
    "loss_func = torch.nn.L1Loss(reduce=False, reduction='sum')\n",
    "timeframe = \"1m\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "if vol:\n",
    "    trainset = PricesVol(\"data/BINANCE_PERP_close_train.npy\", \"data/BINANCE_PERP_volume_train.npy\", seq_length, shift=shift, center=center, norm=norm, tgt_step=tgt_step)\n",
    "    testset = PricesVol(\"data/BINANCE_PERP_close_test.npy\", \"data/BINANCE_PERP_volume_test.npy\", seq_length, shift=shift, center=center, norm=norm, tgt_step=tgt_step)\n",
    "    model = Temporal_Conv_Transformer_Vol(seq_length = seq_length, feature_size=feature_size, dropout=dropout, num_layers=num_layers)\n",
    "else:\n",
    "    trainset = Prices(\"data/train{}.npy\".format(timeframe), seq_length, shift=shift, center=center, norm=norm, tgt_step=tgt_step)\n",
    "    testset = Prices(\"data/test{}.npy\".format(timeframe), seq_length, shift=shift, center=center, norm=norm, tgt_step=tgt_step)\n",
    "    model = Temporal_Conv_Transformer(seq_length = seq_length, feature_size=feature_size, out_channels=out_channels, dropout=dropout, num_layers=num_layers, nhead=nhead)\n",
    "model = model.to(device)\n",
    "#trans_model = Transformer(seq_length = seq_length, feature_size=1, dropout=0.1)\n",
    "#conv_model = Conv(seq_length = seq_length)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, num_workers=0, shuffle=True, drop_last=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=0, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5161287-d4e2-4e74-bbcc-48269e5ad1d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5161287-d4e2-4e74-bbcc-48269e5ad1d8",
    "outputId": "e4af58a4-b01e-46c8-e952-0b243a804aea",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain test:\n",
      "pred: \n",
      " tensor([0.0548, 0.1200, 0.0206, 0.0463, 0.0846]) \n",
      "tgt: \n",
      " tensor([ 28.4004, -16.8984,  15.8008,  -3.9004,  -4.5000]) \n",
      "mus: \n",
      " tensor([ 0.0279,  0.0729,  0.0172, -0.1226,  0.1147]) \n",
      "stds: \n",
      " tensor([ 0.1271,  0.0392, -0.1182, -0.1985, -0.0861]) \n",
      "eps: \n",
      " tensor([ 0.2116,  1.2010,  0.0291,  0.8509, -0.3499])\n",
      "Predictions:  tensor(19.1948) \n",
      "Zero Guess:  tensor(19.1918)\n",
      "Average guess (check if network predicts based on general change):  tensor(-0.0092)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvolb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#train(epoch, trans_model, lr, trainloader, testloader, seq_length, batch_size)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#train(epoch, conv_model, lr, trainloader, testloader, seq_length, batch_size)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\Desktop\\Tradebot\\train_test.py:12\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch, model, lr, trainloader, testloader, seq_length, batch_size, loss_func, volb)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretrain test:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m test(model, testloader, seq_length, batch_size, volb)\n\u001b[1;32m---> 12\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest_conf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvolb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch):\n\u001b[0;32m     14\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\Desktop\\Tradebot\\train_test.py:93\u001b[0m, in \u001b[0;36mtest_conf\u001b[1;34m(model, testloader, seq_length, batch_size, volb)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''src_last = src[:,-1]\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03msrc_last = torch.unsqueeze(src_last, dim=1).repeat(1,seq_length)\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03msrc = torch.sub(src, src_last)\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03mtgt = tgt - src_last[:,0]'''\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 93\u001b[0m     prediction, mus, stds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m mu_signs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39msign(mus)\n\u001b[0;32m     95\u001b[0m tgt_signs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39msign(tgt)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rl-proj\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Desktop\\Tradebot\\model.py:117\u001b[0m, in \u001b[0;36mTemporal_Conv_Transformer_Vol.forward\u001b[1;34m(self, src, vol, eps)\u001b[0m\n\u001b[0;32m    115\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mswapaxes(x,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    116\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_enc(x)\n\u001b[1;32m--> 117\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    119\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rl-proj\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rl-proj\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:238\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    236\u001b[0m         output \u001b[38;5;241m=\u001b[39m mod(output, src_mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    241\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rl-proj\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rl-proj\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:437\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    417\u001b[0m     tensor_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         src,\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39min_proj_weight,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    431\u001b[0m     )\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39mhas_torch_function(tensor_args) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    433\u001b[0m             \u001b[38;5;66;03m# We have to use a list comprehension here because TorchScript\u001b[39;00m\n\u001b[0;32m    434\u001b[0m             \u001b[38;5;66;03m# doesn't support generator expressions.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m             \u001b[38;5;28mall\u001b[39m([(x\u001b[38;5;241m.\u001b[39mis_cuda \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(x\u001b[38;5;241m.\u001b[39mdevice)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tensor_args]) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    436\u001b[0m             (\u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m([\u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tensor_args]))):\n\u001b[1;32m--> 437\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformer_encoder_layer_fwd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m            \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_relu_or_gelu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# norm_first, currently not supported\u001b[39;49;00m\n\u001b[0;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m            \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# TODO: split into two args\u001b[39;49;00m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m x \u001b[38;5;241m=\u001b[39m src\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_first:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(epoch, model, lr, trainloader, testloader, seq_length, batch_size, loss_func = loss_func, volb=vol)\n",
    "#train(epoch, trans_model, lr, trainloader, testloader, seq_length, batch_size)\n",
    "#train(epoch, conv_model, lr, trainloader, testloader, seq_length, batch_size)\n",
    "if not os.path.exists(\"model\"):\n",
    "    os.makedirs(\"model\")\n",
    "PATH = f\"model/pred_model_{timeframe}_len_{seq_length}_shift_{shift}_epoch_{epoch}_lr_{lr}.pt\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1825c55b-d8ce-4ec2-92c2-24c938a05394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(max(1, torch.tensor([0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b224a6-63f3-4e23-be38-aeba10d3de5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8b224a6-63f3-4e23-be38-aeba10d3de5e",
    "outputId": "105ac9e0-b318-4f24-814b-08639d5d6b2a"
   },
   "outputs": [],
   "source": [
    "model = Temporal_Conv_Transformer_Vol(seq_length = seq_length, feature_size=feature_size, dropout=dropout, num_layers=num_layers)\n",
    "PATH = f\"model/pred_model_vol_{timeframe}_len_{seq_length}_shift_{shift}_epoch_{epoch}_lr_{lr}.pt\"\n",
    "PATH = f\"model/006.pt\"\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "#model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "454533b0-f558-4f60-b9f1-7f266dfa9708",
   "metadata": {
    "id": "454533b0-f558-4f60-b9f1-7f266dfa9708"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=0, shuffle=False, drop_last=True)\n",
    "mus, stds, tgts = test_mus_stds_tgts(model, testloader, seq_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afca93a8-14d4-4aac-8d08-023592cc6cf6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afca93a8-14d4-4aac-8d08-023592cc6cf6",
    "outputId": "32d4524c-edaf-4973-f337-cd1df630374d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7516)\n",
      "tensor(0.2316) tensor(0.7516) tensor(0.2255)\n",
      "tensor(0.4391)\n",
      "tensor(0.0814) tensor(0.4391) tensor(0.0667)\n",
      "5374 4866 0.5248046875\n",
      "3310 2843 0.5379489679830977\n",
      "0.60087890625\n",
      "tensor(18.7524) tensor(19.6770)\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(torch.abs(mus)))\n",
    "mean_mu = torch.mean(torch.abs(mus))\n",
    "mx_mu = torch.max(torch.abs(mus))\n",
    "med_mu = torch.median(torch.abs(mus))\n",
    "print(mean_mu, mx_mu, med_mu)\n",
    "print(torch.max(torch.abs(stds)))\n",
    "mean_std = torch.mean(torch.abs(stds))\n",
    "mx_std = torch.max(torch.abs(stds))\n",
    "med_std = torch.median(torch.abs(stds))\n",
    "print(mean_std, mx_std, med_std)\n",
    "tgt_t = []\n",
    "tgt_f = []\n",
    "t = 0\n",
    "f = 0\n",
    "tm = 0\n",
    "fm = 0\n",
    "me = 0\n",
    "for ii, mu in enumerate(mus):\n",
    "    me = 0\n",
    "    if torch.abs(mu)>0.25*mx_mu: #and torch.abs(stds[ii])<=0.5*mx_std:\n",
    "        me = 1\n",
    "    if torch.sign(mu)==torch.sign(tgts[ii]):\n",
    "        tgt_t.append(tgts[ii])\n",
    "        t += 1\n",
    "        tm += me*1\n",
    "    else:\n",
    "        tgt_f.append(tgts[ii])\n",
    "        f += 1\n",
    "        fm += me*1\n",
    "print(t,f, t/(t+f))\n",
    "print(tm,fm, tm/(tm+fm))\n",
    "print((tm+fm)/(t+f))\n",
    "print(torch.mean(torch.abs(torch.tensor((tgt_t)))), torch.mean(torch.abs(torch.tensor((tgt_f)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b68c209d-2632-4941-b3d5-bacd26091136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accs = test_conf(model1, testloader, seq_length, batch_size)\\naccs = test_conf_ensemble(model1, model2, testloader, seq_length, batch_size)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Temporal_Conv_Transformer(seq_length = seq_length, feature_size=feature_size, dropout=dropout, num_layers=num_layers)\n",
    "model2 = Temporal_Conv_Transformer(seq_length = seq_length, feature_size=feature_size, dropout=dropout, num_layers=num_layers)\n",
    "\n",
    "PATH1 = f\"model/001.pt\"\n",
    "PATH2 = f\"model/006.pt\"\n",
    "#PATH = f\"model/001.pt\"\n",
    "model1.load_state_dict(torch.load(PATH1, map_location=device))\n",
    "model2.load_state_dict(torch.load(PATH2, map_location=device))\n",
    "#model.train()\n",
    "model1 = model1.to(device)\n",
    "model2 = model2.to(device)\n",
    "\n",
    "'''accs = test_conf(model1, testloader, seq_length, batch_size)\n",
    "accs = test_conf_ensemble(model1, model2, testloader, seq_length, batch_size)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AIwfc2ELw1E4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "AIwfc2ELw1E4",
    "outputId": "d7531a82-3277-490b-b2a4-ee905b28cc2b"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "batch_size=256\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=0, shuffle=False, drop_last=True)\n",
    "_ = test(model, testloader, seq_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb605e-8a06-4daf-9365-5afaf4550222",
   "metadata": {
    "id": "b5eb605e-8a06-4daf-9365-5afaf4550222"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "batch_size =\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=0, shuffle=False, drop_last=True)\n",
    "accs = test_conf(model, testloader, seq_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GaNmVIdgj_tQ",
   "metadata": {
    "id": "GaNmVIdgj_tQ"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "batch_size=1\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=0, shuffle=False, drop_last=True)\n",
    "test_conf_val(model, testloader, seq_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22315b04-d710-44fa-9c83-ae1cc9eb722c",
   "metadata": {
    "id": "22315b04-d710-44fa-9c83-ae1cc9eb722c"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "batch_size=1\n",
    "win = 1000\n",
    "testset = Prices(\"data/2023test{}.npy\".format(timeframe), seq_length, shift=shift, center=center, norm=norm, tgt_step=tgt_step)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=0, shuffle=False, drop_last=False)\n",
    "avgs, tgts = test_conf_time(model, testloader, seq_length, batch_size, avg_win=win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8955b1c-bfd0-4149-9915-51bfd4547251",
   "metadata": {
    "id": "f8955b1c-bfd0-4149-9915-51bfd4547251"
   },
   "outputs": [],
   "source": [
    "avgs = np.asarray(avgs)\n",
    "prices = np.load(\"data/2023test{}.npy\".format(timeframe))\n",
    "prices = (prices-np.mean(prices))/np.std(prices)\n",
    "avg_cent = (avg-np.mean(avgs))/np.std(avgs)\n",
    "plt.plot(avg_cent)\n",
    "plt.plot(prices)\n",
    "plt.show()\n",
    "plt.plot(np.cumsum(np.asarray(torch.tensor(tgts))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QKoL6fwCfCKw",
   "metadata": {
    "id": "QKoL6fwCfCKw"
   },
   "outputs": [],
   "source": [
    "plt.hist((torch.tensor(mus)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eCzSftQw8de6",
   "metadata": {
    "id": "eCzSftQw8de6"
   },
   "outputs": [],
   "source": [
    "\n",
    "sorted, ind = torch.sort(torch.abs(torch.tensor(tgts)), descending=True)\n",
    "print(sorted[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VaqhYKAR7qmt",
   "metadata": {
    "id": "VaqhYKAR7qmt"
   },
   "outputs": [],
   "source": [
    "\n",
    "tgt = []\n",
    "tgt_true = []\n",
    "for ii, mu in enumerate(mus):\n",
    "    if torch.sign(mu)==torch.sign(tgts[ii]):\n",
    "        tgt_true.append(torch.abs(tgts[ii]))\n",
    "    tgt.append(torch.abs(tgts[ii]))\n",
    "print(torch.mean(torch.tensor(tgt)))\n",
    "print(torch.mean(torch.tensor(tgt_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IW7bQNqE7Y8l",
   "metadata": {
    "id": "IW7bQNqE7Y8l"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75beec-9553-4dd2-88ab-b0e92ab2d854",
   "metadata": {
    "id": "cd75beec-9553-4dd2-88ab-b0e92ab2d854",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "lr = 0.00001\n",
    "feature_size = 3\n",
    "num_layers = 3\n",
    "dropout = 0.0\n",
    "batch_size = 100\n",
    "seq_length = 500\n",
    "shift = 260\n",
    "tgt_step = 5\n",
    "center = True\n",
    "norm =  False\n",
    "loss_func = torch.nn.L1Loss(reduce=False, reduction='sum')\n",
    "timeframe = \"5m\"\n",
    "\n",
    "\n",
    "shift = 6\n",
    "trainset = Prices(\"data/train{}.npy\".format(timeframe), seq_length, shift=shift, center=center, norm=norm, tgt_step=tgt_step)\n",
    "testset = Prices(\"data/test{}.npy\".format(timeframe), seq_length, shift=shift, center=center, norm=norm, tgt_step=tgt_step)\n",
    "#model = Temporal_Conv_Transformer(seq_length = seq_length, feature_size=feature_size, dropout=dropout, num_layers=num_layers)\n",
    "#trans_model = Transformer(seq_length = seq_length, feature_size=1, dropout=0.1)\n",
    "#conv_model = Conv(seq_length = seq_length)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, num_workers=0, shuffle=True, drop_last=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=0, shuffle=True, drop_last=True)\n",
    "acc = test_conf(model, testloader, seq_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1efd42-4769-436a-bef0-3c8746fd5bcd",
   "metadata": {
    "id": "5b1efd42-4769-436a-bef0-3c8746fd5bcd"
   },
   "outputs": [],
   "source": [
    "accs_mod = np.zeros((13,30))\n",
    "for ii in range(390):\n",
    "    ind = ii%13\n",
    "    ind2 = int((ii-ind)/13)\n",
    "    #print(ind2)\n",
    "    accs_mod[ind,ind2] += accs[ii]\n",
    "#print(accs_mod)\n",
    "print(np.mean(accs_mod,axis=1))\n",
    "print(np.std(accs_mod,axis=1))\n",
    "#plt.plot(accs_mod/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea1d19-117f-4a89-8963-0f88d066f263",
   "metadata": {
    "id": "a5ea1d19-117f-4a89-8963-0f88d066f263"
   },
   "outputs": [],
   "source": [
    "smo = []\n",
    "for i in range(386):\n",
    "    smo.append(np.mean(accs[i:i+100]))\n",
    "plt.plot(smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c3ff4-4399-4a11-bed1-6e3abe662e0a",
   "metadata": {
    "id": "3c8c3ff4-4399-4a11-bed1-6e3abe662e0a"
   },
   "outputs": [],
   "source": [
    "#testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=0, shuffle=False, drop_last=True)\n",
    "#test(model, testloader, seq_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa61fe3e-0b40-4b7f-be7f-c40c9b5ad785",
   "metadata": {
    "id": "fa61fe3e-0b40-4b7f-be7f-c40c9b5ad785",
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch = 50\n",
    "lr = 0.00001\n",
    "feature_size = 3\n",
    "num_layers = 3\n",
    "dropout = 0.0\n",
    "batch_size = 1\n",
    "seq_length = 500\n",
    "shift = 505\n",
    "tgt_step = 5\n",
    "center = True\n",
    "norm =  False\n",
    "loss_func = torch.nn.L1Loss(reduce=False, reduction='sum')\n",
    "timeframe = \"5m\"\n",
    "\n",
    "\n",
    "trainset = Prices(\"data/train{}.npy\".format(timeframe), seq_length, shift=shift, center=center, norm=norm, tgt_step=tgt_step)\n",
    "testset = Prices(\"data/test{}.npy\".format(timeframe), seq_length, shift=shift, center=center, norm=norm, tgt_step=tgt_step)\n",
    "#model = Temporal_Conv_Transformer(seq_length = seq_length, feature_size=feature_size, dropout=dropout, num_layers=num_layers)\n",
    "#trans_model = Transformer(seq_length = seq_length, feature_size=1, dropout=0.1)\n",
    "#conv_model = Conv(seq_length = seq_length)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, num_workers=0, shuffle=True, drop_last=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=0, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9d5948-a72d-4e18-a189-cd575aae4cf2",
   "metadata": {
    "id": "df9d5948-a72d-4e18-a189-cd575aae4cf2"
   },
   "outputs": [],
   "source": [
    "mean_first = True\n",
    "mean_tgt = 0\n",
    "for ii, (src,tgt) in enumerate(testloader):\n",
    "    #print(src)\n",
    "    #x  = np.linspace()\n",
    "    #plt.plot(src[0])\n",
    "    #if ii>10:\n",
    "     #   break\n",
    "    if mean_first:\n",
    "        mean = src\n",
    "        mean_first=False\n",
    "    else:\n",
    "        mean += src\n",
    "    mean_tgt += tgt\n",
    "#print(mean)\n",
    "plt.plot(mean[0])\n",
    "plt.show()\n",
    "print(mean_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86424ea8",
   "metadata": {
    "id": "86424ea8"
   },
   "outputs": [],
   "source": [
    "### Check expected change in training set against expected change in test set ###\n",
    "tgt_sum = 0\n",
    "for ii, (src,tgt) in enumerate(iter(trainloader)):\n",
    "    src_last = src[:,-1]\n",
    "    src_last = torch.unsqueeze(src_last, dim=1).repeat(1,seq_length)\n",
    "    src = torch.sub(src, src_last)\n",
    "    tgt = tgt - src_last[:,0]\n",
    "    tgt_sum += torch.sum(tgt-src[:,-1])\n",
    "    print((ii+1)*batch_size)\n",
    "print(tgt_sum/((ii+1)*batch_size))\n",
    "tgt_sum = tgt_sum/((ii+1)*batch_size)\n",
    "zero_test_sum = 0\n",
    "test_tgt_sum = 0\n",
    "train_test_sum = 0\n",
    "for ii, (src,tgt) in enumerate(iter(testloader)):\n",
    "    src_last = src[:,-1]\n",
    "    src_last = torch.unsqueeze(src_last, dim=1).repeat(1,seq_length)\n",
    "    src = torch.sub(src, src_last)\n",
    "    tgt = tgt - src_last[:,0]\n",
    "    zero_test_sum += torch.sum(torch.abs(tgt))\n",
    "    test_tgt_sum += torch.sum(tgt)\n",
    "    train_test_sum += torch.sum(torch.abs(tgt-tgt_sum))\n",
    "print(zero_test_sum/((ii+1)*batch_size), train_test_sum/((ii+1)*batch_size), test_tgt_sum/((ii+1)*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561615e8",
   "metadata": {
    "id": "561615e8"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"model/pred_model_5m\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c85251f",
   "metadata": {
    "id": "6c85251f"
   },
   "outputs": [],
   "source": [
    "### check percentage of correct prediction by sign\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=0, shuffle=False, drop_last=False)\n",
    "model.eval()\n",
    "#model.train()\n",
    "test_avg = 0\n",
    "for it in range(100):\n",
    "    sums = 0\n",
    "    nums = 0\n",
    "    tgt_signs = 0\n",
    "    mus = 0\n",
    "    for ii, (src,tgt) in enumerate(iter(testloader)):\n",
    "        nums += src.size()[0]\n",
    "        eps = torch.normal(torch.zeros(src.size()[0]),torch.ones(src.size()[0]))\n",
    "        with torch.no_grad():\n",
    "            prediction, mus, stds = model(src, eps)\n",
    "            #print(mus)\n",
    "        signs = torch.sign(mus)*torch.sign(tgt)\n",
    "        cor_pred_signs = torch.ones(src.size()[0])\n",
    "        cor_pred_signs[torch.where(signs==-1)] = 0\n",
    "        cor_pred_signs = cor_pred_signs*torch.sign(mus)\n",
    "        print(cor_pred_signs.sum())\n",
    "        #print(torch.sign(mus).sum()/src.size()[0])\n",
    "        sums += signs.sum()\n",
    "        tgt_signs += torch.sign(tgt).sum()\n",
    "    test_avg += sums/nums\n",
    "    print(sums/nums)\n",
    "    #print(tgt_signs/nums)\n",
    "print(test_avg/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2604214",
   "metadata": {
    "id": "b2604214"
   },
   "outputs": [],
   "source": [
    "sums = 0\n",
    "nums = 0\n",
    "tgt_signs = 0\n",
    "for ii, (src,tgt) in enumerate(iter(trainloader)):\n",
    "    nums += src.size()[0]\n",
    "    eps = torch.normal(torch.zeros(src.size()[0]),torch.ones(src.size()[0]))\n",
    "    prediction, mus, stds = temp_conv_model(src, eps)\n",
    "    signs = torch.sign(prediction)*torch.sign(tgt)\n",
    "    sums += signs.sum()\n",
    "    tgt_signs += torch.sign(tgt).sum()\n",
    "print(sums/nums)\n",
    "print(tgt_signs/nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba325055",
   "metadata": {
    "id": "ba325055"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e2b869",
   "metadata": {
    "id": "43e2b869"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d55d66",
   "metadata": {
    "id": "d1d55d66"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4379f",
   "metadata": {
    "id": "e4d4379f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
